<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="MRI-data organization" href="mridata_organization.html" /><link rel="prev" title="MRI acquisitions" href="mri_acquisitions.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2023.03.27 -->
        <title>Processing pipelines - Individual Brain Charting documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Individual Brain Charting  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="_static/ibc3.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Individual Brain Charting  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="participants.html">Participants</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mri_acquisitions.html">MRI acquisitions</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Processing pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="mridata_organization.html">MRI-data organization</a></li>
<li class="toctree-l1"><a class="reference internal" href="accessibility.html">Accessibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="experimentaldesign_diagrams.html">Experimental-design diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="section8.html">Acquisition table</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="processing-pipelines">
<h1>Processing pipelines<a class="headerlink" href="#processing-pipelines" title="Permalink to this heading">#</a></h1>
<section id="fmri-preprocessing-pipeline">
<h2>fMRI Preprocessing Pipeline<a class="headerlink" href="#fmri-preprocessing-pipeline" title="Permalink to this heading">#</a></h2>
<p>Source data were preprocessed using <em>PyPreprocess</em>. This library offers
a collection of Python tools to facilitate pipeline runs, reporting and
quality check (<a class="reference external" href="https://github.com/neurospin/pypreprocess">https://github.com/neurospin/pypreprocess</a>). It is built
upon the <em>Nipype</em> library (<a class="reference external" href="http://doi.org/10.3389/fninf.2011.00013">Gorgolewski et al., 2011</a>) v0.12.1, that in
turn launched various commands used to process neuroimaging data. These
commands were taken from the <em>SPM12</em> software package (Wellcome
Department of Imaging Neuroscience, London, UK) v6685, and the <em>FSL</em>
library (Analysis Group, FMRIB, Oxford, UK) v5.0.</p>
<p>All fMRI images, i.e. GE-EPI volumes, were collected twice with reversed
phase-encoding directions, resulting in pairs of images with distortions
going in opposite directions. Susceptibility-induced off-resonance field
was estimated from the two Spin-Echo EPI volumes in reversed
phase-encoding directions. The images were corrected based on the
estimated deformation model, using the <em>topup</em> tool (<a class="reference external" href="http://doi.org/10.1016/S1053-8119(03)00336-7">Andersson, Skare,
and Ashburner 2003</a>) implemented in FSL (<a class="reference external" href="http://doi.org/10.1016/j.neuroimage.2004.07.051">Smith et al., 2004</a>).</p>
<p>Further, the GE-EPI volumes were aligned to each other within each
participant. A rigid body transformation was employed, in which the
average volume of all images was used as reference (<a class="reference external" href="https://doi.org/10.1006/nimg.1995.1019">Friston et al.,
1995</a>). The mean EPI volume was also co-registered onto the corresponding
T1-weighted MPRAGE (anatomical) volume for every participant (<a class="reference external" href="https://doi.org/10.1006/nimg.1997.0290">Ashburner
and Friston 1997</a>). The individual anatomical volumes were then segmented
into tissue types to finally allow for the normalization of both
anatomical and functional data (<a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2005.02.018">Ashburner and Friston 2005</a>). Concretely,
the segmented volumes were used to compute the deformation field for
normalization to the standard MNI152 space. The deformation field was
then applied to the EPI data. In the end, all volumes were resampled to
their original resolution, i.e. 1 mm isotropic for the
T1-weighted MPRAGE images and 1.5 mm for the EPI images.</p>
<section id="model-specification">
<span id="subsubsec-modelspec"></span><h3>Model Specification<a class="headerlink" href="#model-specification" title="Permalink to this heading">#</a></h3>
<p>The fMRI data were analyzed using the <em>General Linear Model</em> (GLM).
Regressors of the model were designed to capture variations in BOLD
response strictly following stimulus timing specifications. They were
estimated through the convolution of temporal representations referring
to the task-conditions with the canonical <em>Hemodynamic Response
Function</em> (HRF), defined according to (<a class="reference external" href="http://doi.org/10.1006/nimg.1997.0306">Friston, Fletcher, et al.,
1998</a>) and (<a class="reference external" href="https://doi.org/10.1002/mrm.1910390109">Friston, Josephs, et al., 1998</a>).</p>
<p>The temporal profile of the conditions was characterized by boxcar
functions. To build such models, paradigm descriptors grouped in
triplets (i.e. onset time, duration and trial type according to BIDS
Specification) were determined from the log files’ registries generated
by the stimulus-delivery software.</p>
<p>To account for small fluctuations in the latency of the HRF peak
response, additional regressors were computed based on the convolution
of the same task-conditions profile with the time derivative of the HRF.</p>
<p>Nuisance regressors were also added to the design matrix in order to
minimize the final residual error. To remove signal variance associated
with spurious effects arising from movements, six temporal regressors
were defined for the motion parameters. Further, the first five
principal components of the signal, extracted from voxels showing the 5%
highest variance, were also regressed to capture physiological noise
(<a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2007.04.042">Behzadi et al., 2007</a>).</p>
<p>In addition, a discrete-cosine transform set was applied for high-pass filtering (cutoff = 128 seconds). Model specification was implemented using <em>Nistats</em> library v0.0.1b, a Python module devoted to statistical analysis of fMRI data (<a class="reference external" href="https://nistats.github.io">https://nistats.github.io</a>), which leverages <em>Nilearn</em> (<a class="reference external" href="https://doi.org/10.3389/fninf.2014.00014">Abraham et al., 2014</a>), a Python library for statistical learning on neuroimaging data (<a class="reference external" href="https://nilearn.github.io/">https://nilearn.github.io/</a>).</p>
</section>
<section id="model-estimation">
<span id="subsubsec-modelest"></span><h3>Model Estimation<a class="headerlink" href="#model-estimation" title="Permalink to this heading">#</a></h3>
<p>In order to restrict GLM parameters estimation to voxels inside
functional brain regions, a brain mask was extracted from the mean EPI
volume. The procedure implemented in the Nilearn software simply
thresholds the mean fMRI image of each subject in order to separate
brain tissue from background, and performs then a morphological opening
of the resulting image to remove spurious voxels.</p>
<p>Regarding noise modeling, a first-order autoregressive model was used in
the maximum likelihood estimation procedure.</p>
<p>A mass-univariate GLM fit was applied separately to the preprocessed
GE-EPI data of each run with respect to a specific task. Parameter
estimates pertaining to the experimental conditions were thus computed,
along with the respective covariance at every voxel. Various contrasts
(linear combinations of the effects), were then defined, referring only
to differences in evoked responses between either <em>(i)</em> two
conditions-of-interest or <em>(ii)</em> one condition-of-interest and baseline.
GLM estimation and subsequent statistical analyses were also implemented
using Nistats v0.1. fMRI data analysis was first run on unsmoothed data
and, afterwards, on data smoothed with a 5mm full-width-at-half-maximum
kernel. Such procedure allows for increased <em>Signal-to-Noise Ratio</em>
(SNR) and it facilitates between-image comparison.</p>
</section>
</section>
<section id="dwi-preprocessing-pipeline">
<h2>DWI Preprocessing Pipeline<a class="headerlink" href="#dwi-preprocessing-pipeline" title="Permalink to this heading">#</a></h2>
<p>The DWI data were preprocessed using <em>MRtrix3</em> (<a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2019.116137">Tournier et al., 2019</a>)
and <em>FSL</em> (<a class="reference external" href="http://doi.org/10.1016/j.neuroimage.2004.07.051">Smith et al., 2004</a>). The images were first denoised using the
Marchenko-Pastur PCA method (<a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2016.08.016">Veraart et al., 2016</a>, <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2019.06.039">Cordero-Grande et
al. 2019</a>) implemented with the MRtrix <code class="code docutils literal notranslate"><span class="pre">dwidenoise</span></code> function. Then, to
correct the distortions due to inhomogeneities of the magnetic field,
FSL’s <em>topup</em> (<a class="reference external" href="http://doi.org/10.1016/S1053-8119(03)00336-7">Andersson, Skare, and Ashburner 2003</a>) and <em>eddy</em>
(<a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2015.10.019">Andersson and Sotiropoulos 2016</a>) correction were used. The <em>topup</em>
method estimates the susceptibility-induced distortions of the subject’s
head from the pairs of images with opposite distortion patterns (because
of acquisition with opposite phase-encoding directions -
anterior-to-posterior and posterior-to-anterior). This was followed by
<em>eddy</em> correction that corrects for eddy current-induced distortions,
which are a consequence of rapid switching of the diffusion gradients.
No bias field correction was done.</p>
<section id="fiber-orientation-density-estimation-and-tractography">
<span id="subsubsec-fodtract"></span><h3>Fiber Orientation Density Estimation and Tractography<a class="headerlink" href="#fiber-orientation-density-estimation-and-tractography" title="Permalink to this heading">#</a></h3>
<p>From this preprocessed data, the response functions (required for fiber
orientation density estimation) for each of white matter, grey matter,
and cerebro-spinal fluid tissue types were estimated using <code class="code docutils literal notranslate"><span class="pre">dwi2response</span>
<span class="pre">dhollander</span></code> the MRtrix implementation of the Dhollander algorithm
(<a class="reference external" href="https://archive.ismrm.org/2019/0555.html">Dhollander et al., 2019</a>). These derived response functions were then
used to estimate the amount of diffusion in three orthogonal directions
(known as fiber orientation density estimation) using multi-shell
multi-tissue constrained deconvolution method implemented under
<code class="code docutils literal notranslate"><span class="pre">dwi2fod</span></code> in MRtrix.</p>
<p>Then to seed the streamlines from the grey matter-white matter interface
in the next step, a mask of this grey matter-white matter boundary was
first generated using the high-resolution segmented T1 image with the
<code class="code docutils literal notranslate"><span class="pre">5tt2gmwmi</span></code> function in MRtrix. Finally, using this grey matter-white
matter boundary mask and the estimated white-matter fiber orientation
density, the second-order integration over fiber orientation
distributions (iFOD2) method (<a class="reference external" href="https://archive.ismrm.org/2010/1670.html">Tournier et al., 2010</a>) was used to estimate
the streamline tracts. For this, the MRtrix function <code class="code docutils literal notranslate"><span class="pre">tckgen</span></code>, was used
to generate <span class="math notranslate nohighlight">\(10^{7}\)</span> streamlines with a maximum length of 250 mm
and the fiber orientation density amplitude cut-off set at 0.6.</p>
</section>
<section id="structural-connectivity-estimation">
<span id="subsubsec-strucconn"></span><h3>Structural Connectivity Estimation<a class="headerlink" href="#structural-connectivity-estimation" title="Permalink to this heading">#</a></h3>
<p>These streamlines were then warped into the MNI152 space using <em>ANTs</em>
(<a class="reference external" href="https://psychiatry.ucsd.edu/research/programs-centers/snl/_files/ants2.pdf">Avants et al., 2009</a>) image registration described
<a class="reference external" href="https://community.mrtrix.org/t/registration-using-transformations-generated-from-other-packages/2259">here</a>.
The structural connectivity matrix was then calculated for the warped
streamlines in MNI space for 400 parcels of the Schaefer atlas (<a class="reference external" href="https://doi.org/10.1093/cercor/bhx179">Schaefer et al., 2018</a>) using <code class="code docutils literal notranslate"><span class="pre">tck2connectome</span></code> from MRtrix. Each value in this
connectivity matrix was the sum of the contribution (SIFT2 weights
(<a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2015.06.092">Smith et al., 2015</a>) calculated using :code: <cite>tcksift2</cite>) of each streamline
(between any two given parcels) to the overall fiber orientation density
and was normalized by the volume of the two parcels (using parameter
<code class="code docutils literal notranslate"><span class="pre">-scale_invnondevol</span></code> with <code class="code docutils literal notranslate"><span class="pre">tck2connectome</span></code>).</p>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="mridata_organization.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">MRI-data organization</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="mri_acquisitions.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">MRI acquisitions</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Bertrand Thirion
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Processing pipelines</a><ul>
<li><a class="reference internal" href="#fmri-preprocessing-pipeline">fMRI Preprocessing Pipeline</a><ul>
<li><a class="reference internal" href="#model-specification">Model Specification</a></li>
<li><a class="reference internal" href="#model-estimation">Model Estimation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#dwi-preprocessing-pipeline">DWI Preprocessing Pipeline</a><ul>
<li><a class="reference internal" href="#fiber-orientation-density-estimation-and-tractography">Fiber Orientation Density Estimation and Tractography</a></li>
<li><a class="reference internal" href="#structural-connectivity-estimation">Structural Connectivity Estimation</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>